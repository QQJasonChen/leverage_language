// Hybrid YouTube Transcript Content Script
// Combines real-time caption monitoring with API attempts

(function() {
  'use strict';

  console.log('üé¨ HYBRID YouTube transcript content script loaded');

  // Caption collection state with time-window approach
  let captionCollection = {
    segments: [],
    isCollecting: false,
    startTime: 0,
    lastCaptionTime: 0,
    currentVideoTime: 0,
    lastCollectedTimestamp: 0,
    timeSegmentThreshold: 10, // ‚úÖ FIX: Lower threshold - create new segment if time gap > 10s (user jumped)
    // ‚úÖ NEW: Automatic chunking within collection sessions
    chunkDurationThreshold: 45, // Seconds - create new chunk every 45 seconds
    currentChunkStartTime: 0,
    currentChunkStartTimestamp: null,
    chunkCounter: 0,
    // ‚úÖ NEW: Time-window collection approach
    timeWindow: {
      startTime: null,
      endTime: null,
      textBuffer: [],
      windowDuration: 2.5, // Collect for 2.5 seconds before processing
      lastProcessedTime: 0
    }
  };

  // Listen for requests from extension
  chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
    console.log('üé¨ HYBRID transcript content script received message:', request);
    
    // Handle ping test
    if (request.action === 'ping') {
      console.log('üèì Ping received, sending pong...');
      sendResponse({ 
        pong: true, 
        timestamp: Date.now(), 
        url: window.location.href,
        videoId: extractVideoId(),
        hasPlayer: !!document.querySelector('#movie_player'),
        isCollecting: captionCollection.isCollecting,
        collectedSegments: captionCollection.segments.length
      });
      return false;
    }
    
    // Handle transcript requests
    if (request.action === 'getYouTubeTranscript') {
      console.log('üöÄ HYBRID Processing transcript request...');
      getHybridTranscript().then(response => {
        console.log('üì§ HYBRID Sending transcript response:', response);
        sendResponse(response);
      }).catch(error => {
        console.error('‚ùå HYBRID Error in getTranscript:', error);
        sendResponse({ success: false, error: error.message });
      });
      return true;
    }

    // Handle start collection request
    if (request.action === 'startCaptionCollection') {
      const chunkDuration = request.chunkDuration || 45; // Default to 45 seconds
      
      // ‚úÖ NEW: Detect caption type and adapt collection strategy
      const captionType = detectCaptionType();
      console.log('üéØ Caption type detected:', captionType);
      
      if (captionType === 'auto-generated') {
        // Use larger chunks and stream processing for auto-captions
        console.log('ü§ñ Using auto-caption collection strategy');
        startAutoGeneratedCaptionCollection(Math.max(chunkDuration, 20)); // Min 20 seconds for auto
      } else {
        // Use current method for manual captions
        console.log('üìù Using manual caption collection strategy');
        startCaptionCollection(chunkDuration);
      }
      
      sendResponse({ 
        success: true, 
        message: `Caption collection started (${captionType} detected)`,
        captionType: captionType
      });
      return false;
    }

    // Handle stop collection request
    if (request.action === 'stopCaptionCollection') {
      const result = stopCaptionCollection();
      sendResponse({ success: true, segments: result.segments, duration: result.duration });
      return false;
    }

    // Handle seek to timestamp request
    if (request.action === 'seekToTime') {
      console.log('‚è© HYBRID Seeking to time:', request.time);
      
      // ‚úÖ FIX: More robust YouTube player seeking with latest methods
      console.log('üîç HYBRID Looking for YouTube player...');
      
      let seekSuccess = false;
      
      // Method 1: Direct video element manipulation (most reliable)
      const videos = document.querySelectorAll('video');
      console.log('üì∫ Found', videos.length, 'video elements');
      
      for (const video of videos) {
        if (video.duration && video.duration > 0) {
          try {
            console.log('üéØ Attempting to set currentTime to', request.time, 'on video element');
            video.currentTime = request.time;
            seekSuccess = true;
            console.log('‚úÖ HYBRID Video element seek successful');
            break;
          } catch (e) {
            console.log('‚ùå Video element seek failed:', e.message);
          }
        }
      }
      
      // Method 2: Try YouTube player object methods
      if (!seekSuccess) {
        const player = document.querySelector('#movie_player');
        if (player) {
          console.log('üéÆ Found movie_player, trying seekTo...');
          if (typeof player.seekTo === 'function') {
            try {
              player.seekTo(request.time, true);
              seekSuccess = true;
              console.log('‚úÖ HYBRID movie_player.seekTo successful');
            } catch (e) {
              console.log('‚ùå movie_player.seekTo failed:', e.message);
            }
          }
        }
      }
      
      // Method 3: Try window.ytplayer
      if (!seekSuccess && window.ytplayer) {
        console.log('üåê Trying window.ytplayer...');
        try {
          if (typeof window.ytplayer.seekTo === 'function') {
            window.ytplayer.seekTo(request.time);
            seekSuccess = true;
            console.log('‚úÖ HYBRID window.ytplayer.seekTo successful');
          }
        } catch (e) {
          console.log('‚ùå window.ytplayer.seekTo failed:', e.message);
        }
      }
      
      // Method 4: Try dispatching keyboard events (space + arrow keys simulation)
      if (!seekSuccess) {
        console.log('‚å®Ô∏è Trying keyboard simulation fallback...');
        try {
          // Focus the video player first
          const playerContainer = document.querySelector('#movie_player, .html5-video-player');
          if (playerContainer) {
            playerContainer.focus();
            
            // Create a custom seeking approach by simulating time updates
            const video = playerContainer.querySelector('video');
            if (video) {
              // Pause, seek, then resume
              const wasPlaying = !video.paused;
              video.pause();
              video.currentTime = request.time;
              
              if (wasPlaying) {
                setTimeout(() => video.play(), 100);
              }
              
              seekSuccess = true;
              console.log('‚úÖ HYBRID Keyboard simulation successful');
            }
          }
        } catch (e) {
          console.log('‚ùå Keyboard simulation failed:', e.message);
        }
      }
      
      if (seekSuccess) {
        sendResponse({ success: true, time: request.time });
      } else {
        console.error('‚ùå HYBRID All seek methods failed');
        sendResponse({ success: false, error: 'All seek methods failed - YouTube player may be protected' });
      }
      return false;
    }

    // Handle video metadata request
    if (request.action === 'getVideoMetadata') {
      console.log('üì∫ Getting video metadata...');
      const metadata = collectVideoMetadata();
      sendResponse(metadata);
      return false;
    }
  });

  function extractVideoId() {
    const url = window.location.href;
    const match = url.match(/[?&]v=([^&]+)/);
    return match ? match[1] : null;
  }

  function collectVideoMetadata() {
    // Collect comprehensive video metadata from YouTube page
    const videoId = extractVideoId();
    
    // Extract title - try multiple selectors
    let title = null;
    const titleSelectors = [
      'h1.ytd-video-primary-info-renderer',
      'h1.title.style-scope.ytd-video-primary-info-renderer', 
      'h1[class*="title"]',
      'meta[property="og:title"]',
      'title'
    ];
    
    for (const selector of titleSelectors) {
      const element = document.querySelector(selector);
      if (element) {
        if (element.tagName === 'META') {
          title = element.getAttribute('content');
        } else {
          title = element.textContent?.trim();
        }
        if (title && title !== 'YouTube' && !title.includes('undefined')) {
          break;
        }
      }
    }
    
    // Extract channel name - try multiple selectors  
    let channel = null;
    const channelSelectors = [
      'ytd-channel-name#channel-name a',
      'ytd-channel-name .yt-simple-endpoint',
      '.ytd-channel-name a',
      '.channel-name a',
      'a.yt-simple-endpoint[href*="/channel/"]',
      'a.yt-simple-endpoint[href*="/@"]'
    ];
    
    for (const selector of channelSelectors) {
      const element = document.querySelector(selector);
      if (element && element.textContent?.trim()) {
        channel = element.textContent.trim();
        break;
      }
    }
    
    // Fallback: try to extract from page title
    if (!title || !channel) {
      const pageTitle = document.title;
      if (pageTitle && pageTitle.includes(' - YouTube')) {
        const parts = pageTitle.replace(' - YouTube', '').split(' - ');
        if (!title && parts.length > 0) {
          title = parts[0].trim();
        }
        if (!channel && parts.length > 1) {
          channel = parts[parts.length - 1].trim();
        }
      }
    }
    
    console.log('üì∫ Collected video metadata:', { 
      videoId, 
      title: title?.substring(0, 50) + '...', 
      channel 
    });
    
    return {
      videoId: videoId,
      title: title || 'YouTube Video',
      channel: channel || 'Unknown Channel',
      url: window.location.href,
      timestamp: Date.now()
    };
  }

  async function getTranscriptFromPageData() {
    console.log('üîç Searching for transcript data in page...');
    
    try {
      // Method 1: Check ytInitialData for transcript info
      if (window.ytInitialData) {
        const panels = window.ytInitialData?.engagementPanels || [];
        for (const panel of panels) {
          if (panel?.engagementPanelSectionListRenderer?.targetId === 'engagement-panel-searchable-transcript') {
            console.log('üìù Found transcript panel data in ytInitialData');
            // This indicates transcript exists but we need to fetch it
            break;
          }
        }
      }

      // Method 2: Try to intercept transcript network requests
      const videoId = extractVideoId();
      if (!videoId) return null;

      // Look for transcript in various page data locations
      const pageDataSources = [
        // YouTube's player response
        () => {
          const scripts = document.querySelectorAll('script');
          for (const script of scripts) {
            const content = script.textContent || '';
            if (content.includes('captionTracks') && content.includes(videoId)) {
              const match = content.match(/var ytInitialPlayerResponse = ({.+?});/);
              if (match) {
                try {
                  const data = JSON.parse(match[1]);
                  return data?.captions?.playerCaptionsTracklistRenderer;
                } catch (e) {}
              }
            }
          }
          return null;
        },
        // Try window.ytplayer
        () => window.ytplayer?.config?.args?.raw_player_response?.captions?.playerCaptionsTracklistRenderer,
        // Try ytInitialPlayerResponse
        () => window.ytInitialPlayerResponse?.captions?.playerCaptionsTracklistRenderer
      ];

      for (const getSource of pageDataSources) {
        try {
          const captionData = getSource();
          if (captionData?.captionTracks) {
            console.log('üéØ Found caption data in page');
            
            // Get the best track
            const tracks = captionData.captionTracks;
            const track = tracks.find(t => t.vssId?.includes('.asr')) || tracks[0];
            
            if (track?.baseUrl) {
              // Fetch the actual transcript
              const transcript = await fetchTranscriptFromUrl(track.baseUrl);
              if (transcript && transcript.length > 0) {
                return transcript;
              }
            }
          }
        } catch (e) {
          continue;
        }
      }

      // Method 3: Try to get from API endpoint directly
      const apiTranscript = await tryDirectAPIFetch(videoId);
      if (apiTranscript && apiTranscript.length > 0) {
        return apiTranscript;
      }

      return null;
    } catch (error) {
      console.error('‚ùå Failed to get transcript from page data:', error);
      return null;
    }
  }

  async function fetchTranscriptFromUrl(url) {
    console.log('üì• Fetching transcript from URL...');
    
    try {
      // Clean the URL and try different formats
      const baseUrl = url.split('&fmt=')[0];
      const formats = ['srv3', 'json3', 'vtt'];
      
      for (const fmt of formats) {
        const fetchUrl = `${baseUrl}&fmt=${fmt}`;
        console.log('üåê Trying format:', fmt);
        
        const response = await fetch(fetchUrl, {
          method: 'GET',
          credentials: 'include',
          headers: {
            'Accept': 'text/xml, application/xml, application/json, text/vtt'
          }
        });
        
        if (response.ok) {
          const content = await response.text();
          if (content && content.length > 100) {
            console.log('‚úÖ Got transcript content:', content.length, 'chars');
            
            // Parse based on format
            if (fmt === 'srv3' || !fmt) {
              return parseXMLTranscript(content);
            } else if (fmt === 'json3') {
              try {
                const json = JSON.parse(content);
                return parseJSONTranscript(json);
              } catch (e) {
                return parseXMLTranscript(content);
              }
            } else if (fmt === 'vtt') {
              return parseVTTTranscript(content);
            }
          }
        }
      }
    } catch (error) {
      console.error('‚ùå Fetch transcript failed:', error);
    }
    
    return null;
  }

  async function tryDirectAPIFetch(videoId) {
    console.log('üåê Trying direct API fetch for video:', videoId);
    
    // Get current page info for auth
    const scripts = document.querySelectorAll('script');
    let apiKey = null;
    
    for (const script of scripts) {
      const content = script.textContent || '';
      const keyMatch = content.match(/"INNERTUBE_API_KEY":"([^"]+)"/);
      if (keyMatch) {
        apiKey = keyMatch[1];
        break;
      }
    }
    
    if (!apiKey) {
      console.log('‚ùå No API key found');
      return null;
    }
    
    try {
      const response = await fetch(`https://www.youtube.com/youtubei/v1/get_transcript?key=${apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          context: {
            client: {
              clientName: 'WEB',
              clientVersion: '2.0'
            }
          },
          params: videoId
        })
      });
      
      if (response.ok) {
        const data = await response.json();
        // Parse transcript from response
        if (data?.actions) {
          // Extract transcript segments
          console.log('‚úÖ Got transcript from API');
          return parseYouTubeAPIResponse(data);
        }
      }
    } catch (error) {
      console.error('‚ùå Direct API fetch failed:', error);
    }
    
    return null;
  }

  function parseYouTubeAPIResponse(data) {
    // Extract transcript segments from YouTube API response
    const segments = [];
    
    try {
      const transcriptData = data?.actions?.[0]?.updateEngagementPanelAction?.content?.transcriptRenderer?.content?.transcriptSearchPanelRenderer;
      if (transcriptData?.body?.transcriptSegmentListRenderer?.initialSegments) {
        const initialSegments = transcriptData.body.transcriptSegmentListRenderer.initialSegments;
        
        for (const segment of initialSegments) {
          if (segment.transcriptSegmentRenderer) {
            const renderer = segment.transcriptSegmentRenderer;
            const startMs = parseInt(renderer.startMs);
            const endMs = parseInt(renderer.endMs);
            const text = renderer.snippet?.runs?.map(r => r.text).join('') || '';
            
            if (text) {
              segments.push({
                start: startMs / 1000,
                end: endMs / 1000,
                duration: (endMs - startMs) / 1000,
                text: text.trim()
              });
            }
          }
        }
      }
    } catch (e) {
      console.error('‚ùå Failed to parse API response:', e);
    }
    
    return segments;
  }

  async function getHybridTranscript() {
    console.log('üîç HYBRID Starting transcript extraction...');
    
    try {
      const videoId = extractVideoId();
      if (!videoId) {
        throw new Error('Could not extract video ID');
      }
      
      console.log('üìπ HYBRID Video ID:', videoId);

      // Method 1: Direct transcript download (NEW - preferred method)
      let transcript = await downloadCompleteTranscript(videoId);
      if (transcript && transcript.length > 0) {
        console.log('‚úÖ HYBRID Complete transcript downloaded:', transcript.length, 'segments');
        return { success: true, transcript, videoId, method: 'directDownload' };
      }

      // Method 2: Enhanced transcript panel approach
      transcript = await tryTranscriptPanel();
      if (transcript && transcript.length > 0) {
        console.log('‚úÖ HYBRID Transcript via panel:', transcript.length, 'segments');
        return { success: true, transcript, videoId, method: 'transcriptPanel' };
      }

      // Method 3: Use collected captions only if user explicitly collected them
      if (captionCollection.segments.length > 0 && captionCollection.isCollecting === false) {
        console.log('‚úÖ HYBRID Using pre-collected captions:', captionCollection.segments.length, 'segments');
        return { 
          success: true, 
          transcript: [...captionCollection.segments], 
          videoId, 
          method: 'userCollection',
          collectionDuration: (Date.now() - captionCollection.startTime) / 1000
        };
      }

      // Method 4: Try alternative transcript access methods
      transcript = await tryAlternativeTranscriptMethods(videoId);
      if (transcript && transcript.length > 0) {
        console.log('‚úÖ HYBRID Alternative method:', transcript.length, 'segments');
        return { success: true, transcript, videoId, method: 'alternativeMethod' };
      }

      // Method 5: As last resort, try the metadata but with a better message
      const metadataTranscript = await tryVideoMetadata();
      if (metadataTranscript && metadataTranscript.length > 0) {
        console.log('‚ö†Ô∏è Only metadata available - no real captions found');
        return { 
          success: true, 
          transcript: metadataTranscript, 
          videoId, 
          method: 'metadataOnly',
          warning: 'No captions available. Try: 1) Enable CC button on video, 2) Use "Collect" feature while playing, 3) Open YouTube transcript panel manually.'
        };
      }

      throw new Error('No transcript available. Try: 1) Enable CC on video, 2) Use "Collect" button while playing video, 3) Check if video has captions at all.');
      
    } catch (error) {
      console.error('‚ùå HYBRID transcript extraction failed:', error);
      return { success: false, error: error.message };
    }
  }

  async function tryTranscriptPanel() {
    console.log('üîç HYBRID Method 1: Direct transcript download attempt...');
    
    try {
      // First try to get transcript data from page without UI interaction
      const transcriptData = await getTranscriptFromPageData();
      if (transcriptData && transcriptData.length > 0) {
        console.log('‚úÖ Got transcript from page data:', transcriptData.length, 'segments');
        return transcriptData;
      }
      
      // If that fails, try the panel approach
      console.log('üìã Trying transcript panel UI...');
      let transcriptPanel = document.querySelector('ytd-transcript-renderer, ytd-engagement-panel-section-list-renderer[target-id="engagement-panel-searchable-transcript"]');
      
      if (!transcriptPanel) {
        // Try to open transcript panel with better selectors
        const expandButton = document.querySelector('#primary #expand, #description #expand, ytd-text-inline-expander #expand');
        if (expandButton) {
          console.log('üîò HYBRID Clicking expand button...');
          expandButton.click();
          await sleep(1000);
        }
        
        // Look for show transcript button
        const transcriptButtons = Array.from(document.querySelectorAll('button, yt-button-shape')).filter(el => {
          const text = (el.textContent || el.getAttribute('aria-label') || '').toLowerCase();
          return text.includes('transcript') || text.includes('ÊñáÂ≠óË®òÈåÑ') || text.includes('Â≠óÂπï');
        });
        
        if (transcriptButtons.length > 0) {
          console.log('üìù HYBRID Found', transcriptButtons.length, 'potential transcript buttons');
          for (const btn of transcriptButtons) {
            try {
              btn.click();
              await sleep(2000);
              
              // Check if transcript panel opened
              transcriptPanel = document.querySelector('ytd-transcript-renderer, ytd-engagement-panel-section-list-renderer[target-id="engagement-panel-searchable-transcript"]');
              if (transcriptPanel) break;
            } catch (e) {
              continue;
            }
          }
        }
      }
      
      if (transcriptPanel) {
        // Wait a bit for segments to load
        await sleep(1500);
        
        // Extract segments from transcript panel - try multiple selectors
        const segmentSelectors = [
          'ytd-transcript-segment-renderer',
          'ytd-transcript-body-renderer [role="button"]',
          '.ytd-transcript-segment-list-renderer',
          '#segments-container ytd-transcript-segment-renderer',
          'tp-yt-paper-button.ytd-transcript-segment-renderer',
          '[class*="cue-group"]', // For newer YouTube UI
          '.ytd-transcript-body-renderer .segment'
        ];
        
        let segments = [];
        for (const selector of segmentSelectors) {
          segments = transcriptPanel.querySelectorAll(selector);
          if (segments.length > 0) {
            console.log('üìù HYBRID Found', segments.length, 'segments with selector:', selector);
            break;
          }
        }
        
        if (segments.length > 0) {
          const transcript = extractFromPanelSegments(segments);
          if (transcript && transcript.length > 10) { // Ensure we have substantial content
            return transcript;
          } else {
            console.log('‚ö†Ô∏è HYBRID Panel segments too few:', transcript?.length || 0);
          }
        } else {
          console.log('‚ùå HYBRID No segments found in transcript panel');
        }
      }
      
      return null;
    } catch (error) {
      console.error('‚ùå HYBRID Transcript panel method failed:', error);
      return null;
    }
  }

  function extractFromPanelSegments(segments) {
    const transcript = [];
    
    segments.forEach((segment, index) => {
      try {
        const timeElement = segment.querySelector('.segment-timestamp, [class*="timestamp"]');
        const textElement = segment.querySelector('.segment-text, [class*="text"]');
        
        let timeText = timeElement?.textContent?.trim() || '';
        let captionText = textElement?.textContent?.trim() || '';
        
        // Fallback: extract from full text
        if (!timeText || !captionText) {
          const fullText = segment.textContent?.trim() || '';
          const timeMatch = fullText.match(/(\d{1,2}):(\d{2})/);
          
          if (timeMatch) {
            timeText = timeMatch[0];
            captionText = fullText.replace(timeMatch[0], '').trim();
          }
        }
        
        if (timeText && captionText) {
          const startTime = parseTimestamp(timeText);
          if (!isNaN(startTime)) {
            transcript.push({
              start: startTime,
              end: startTime + 3,
              duration: 3,
              text: captionText
            });
          }
        }
      } catch (e) {
        console.log(`‚ùå HYBRID Error processing segment ${index}:`, e);
      }
    });
    
    return transcript;
  }

  async function smartCaptionCollection() {
    console.log('üîç HYBRID Method 2: Smart caption collection...');
    
    try {
      // Enable captions if not already enabled
      const ccButton = document.querySelector('.ytp-subtitles-button');
      if (ccButton && ccButton.getAttribute('aria-pressed') !== 'true') {
        console.log('üîò HYBRID Enabling captions...');
        ccButton.click();
        await sleep(2000);
      }
      
      // Start monitoring captions for a short period
      console.log('üì° HYBRID Starting caption monitoring...');
      const monitoringTime = 10000; // 10 seconds
      const collectedCaptions = await monitorCaptionsForPeriod(monitoringTime);
      
      if (collectedCaptions.length > 0) {
        console.log('üìù HYBRID Collected', collectedCaptions.length, 'caption segments');
        return collectedCaptions;
      }
      
      return null;
    } catch (error) {
      console.error('‚ùå HYBRID Smart collection failed:', error);
      return null;
    }
  }

  async function monitorCaptionsForPeriod(duration) {
    return new Promise((resolve) => {
      const captions = [];
      const startTime = Date.now();
      let lastCaptionText = '';
      
      const monitor = setInterval(() => {
        const captionElements = document.querySelectorAll('.ytp-caption-segment, .captions-text, .caption-visual-line');
        
        if (captionElements.length > 0) {
          const currentText = Array.from(captionElements)
            .map(el => el.textContent?.trim())
            .filter(text => text && text !== lastCaptionText)
            .join(' ');
          
          if (currentText && currentText !== lastCaptionText) {
            const player = document.querySelector('#movie_player');
            const currentTime = player && player.getCurrentTime ? player.getCurrentTime() : 0;
            
            captions.push({
              start: currentTime,
              end: currentTime + 3,
              duration: 3,
              text: currentText,
              timestamp: Date.now()
            });
            
            lastCaptionText = currentText;
            console.log('üìù HYBRID Captured caption:', currentText.substring(0, 50) + '...');
          }
        }
        
        // Stop monitoring after duration
        if (Date.now() - startTime > duration) {
          clearInterval(monitor);
          resolve(captions);
        }
      }, 500); // Check every 500ms
    });
  }

  async function getCurrentCaptions() {
    console.log('üîç HYBRID Method 3: Getting available captions with quick scan...');
    
    try {
      // Enable captions if needed
      const ccButton = document.querySelector('.ytp-subtitles-button');
      if (ccButton && ccButton.getAttribute('aria-pressed') !== 'true') {
        ccButton.click();
        await sleep(2000);
      }
      
      // Try to collect captions by quickly scanning through video
      const player = document.querySelector('#movie_player');
      if (!player || !player.getDuration) {
        return null;
      }
      
      const duration = player.getDuration();
      const segments = [];
      const scanInterval = 10; // Scan every 10 seconds
      
      console.log('üîÑ HYBRID Quick scanning video for captions...');
      
      // Save current time
      const originalTime = player.getCurrentTime();
      
      // Scan through video at intervals
      for (let time = 0; time < Math.min(duration, 60); time += scanInterval) {
        player.seekTo(time);
        await sleep(1000); // Wait for captions to load
        
        const captionElements = document.querySelectorAll('.ytp-caption-segment, .captions-text, .caption-visual-line');
        const captionText = Array.from(captionElements)
          .map(el => el.textContent?.trim())
          .filter(text => text)
          .join(' ');
        
        if (captionText) {
          segments.push({
            start: time,
            end: time + scanInterval,
            duration: scanInterval,
            text: captionText
          });
          console.log(`üìù HYBRID Found caption at ${time}s:`, captionText.substring(0, 50) + '...');
        }
      }
      
      // Restore original time
      player.seekTo(originalTime);
      
      if (segments.length > 5) {
        console.log('‚úÖ HYBRID Quick scan found', segments.length, 'caption segments');
        return segments;
      }
      
      return null;
    } catch (error) {
      console.error('‚ùå HYBRID Current captions failed:', error);
      return null;
    }
  }

  function detectCaptionType() {
    // ‚úÖ NEW: Detect if captions are auto-generated or manual
    try {
      // Method 1: Check caption settings button for auto-generated indicators
      const settingsButton = document.querySelector('.ytp-subtitles-button, .ytp-settings-button');
      if (settingsButton) {
        // Look for auto-generated indicators in DOM
        const autoIndicators = document.querySelectorAll('[aria-label*="auto-generated"], [title*="auto-generated"], .caption-window .auto-generated');
        if (autoIndicators.length > 0) {
          return 'auto-generated';
        }
      }
      
      // Method 2: Sample current captions and analyze pattern
      const captionElements = document.querySelectorAll('.caption-window .ytp-caption-segment, .ytp-caption-segment, .captions-text');
      if (captionElements.length > 0) {
        const sampleTexts = Array.from(captionElements).slice(-3).map(el => el.textContent || '').filter(text => text.length > 10);
        
        if (sampleTexts.length >= 2) {
          // Check for auto-generated characteristics
          const characteristics = [
            // Long run-on sentences without proper punctuation
            sampleTexts.some(text => text.length > 100 && !text.includes('.')),
            // Missing capitalization at sentence starts
            sampleTexts.some(text => text.length > 20 && /^[a-z]/.test(text.trim())),
            // Overlap patterns between consecutive segments
            sampleTexts.length >= 2 && this.hasOverlapPattern(sampleTexts)
          ];
          
          if (characteristics.filter(Boolean).length >= 2) {
            return 'auto-generated';
          }
        }
      }
      
      // Method 3: Check video metadata for auto-caption indicator
      const videoMeta = document.querySelector('meta[property="og:description"], #description');
      if (videoMeta && videoMeta.content && videoMeta.content.toLowerCase().includes('auto-generated')) {
        return 'auto-generated';
      }
      
      return 'manual';
    } catch (error) {
      console.log('‚ö†Ô∏è Caption detection error:', error);
      return 'unknown'; // Default to manual collection method
    }
  }

  function hasOverlapPattern(texts) {
    // Check if consecutive caption segments have overlapping content
    for (let i = 1; i < texts.length; i++) {
      const current = texts[i].toLowerCase().trim();
      const previous = texts[i-1].toLowerCase().trim();
      
      // Look for significant word overlap
      const currentWords = current.split(' ');
      const previousWords = previous.split(' ');
      
      if (currentWords.length > 5 && previousWords.length > 5) {
        const lastThreeWords = previousWords.slice(-3).join(' ');
        if (current.includes(lastThreeWords)) {
          return true;
        }
      }
    }
    return false;
  }

  function startAutoGeneratedCaptionCollection(chunkDuration = 25) {
    console.log('ü§ñ Starting AUTO-GENERATED caption collection with', chunkDuration, 'second chunks');
    
    // Use larger chunks and different processing for auto-captions
    captionCollection.isCollecting = true;
    captionCollection.startTime = Date.now();
    captionCollection.chunkDurationThreshold = chunkDuration;
    captionCollection.autoGenerated = true; // Mark as auto-generated
    captionCollection.streamBuffer = ''; // Buffer for stream reconstruction
    captionCollection.lastProcessedText = ''; // Track processed content
    
    console.log('‚úÖ Auto-generated caption collection started');
  }

  function processTimeWindowCaption(currentText, timestampInSeconds, extractedTimestamp, videoId, youtubeLink, isNewChunk) {
    // ‚úÖ NEW: Time-window based collection to prevent fragments and duplicates
    console.log('üïê Time-window processing:', currentText.substring(0, 40) + '...');
    
    // Initialize time window if needed
    if (!captionCollection.timeWindow.startTime) {
      captionCollection.timeWindow.startTime = timestampInSeconds;
      captionCollection.timeWindow.endTime = timestampInSeconds + captionCollection.timeWindow.windowDuration;
      captionCollection.timeWindow.textBuffer = [];
      console.log(`üèÅ Started new time window: ${extractedTimestamp} ‚Üí ${captionCollection.timeWindow.windowDuration}s`);
    }
    
    // Check if current caption fits in the current window
    const isInCurrentWindow = timestampInSeconds <= captionCollection.timeWindow.endTime;
    const hasSignificantGap = timestampInSeconds - captionCollection.timeWindow.lastProcessedTime > 8; // 8s gap = new window
    
    // Process current window if it's complete or we have a significant time gap
    if (!isInCurrentWindow || hasSignificantGap) {
      // Process the accumulated window first
      if (captionCollection.timeWindow.textBuffer.length > 0) {
        createSegmentFromTimeWindow(videoId, youtubeLink);
      }
      
      // Start new window
      captionCollection.timeWindow.startTime = timestampInSeconds;
      captionCollection.timeWindow.endTime = timestampInSeconds + captionCollection.timeWindow.windowDuration;
      captionCollection.timeWindow.textBuffer = [];
      
      if (hasSignificantGap) {
        console.log(`‚è≠Ô∏è Significant gap detected (${Math.floor(timestampInSeconds - captionCollection.timeWindow.lastProcessedTime)}s) - forcing new window`);
      }
    }
    
    // Add current caption to the window buffer (avoid duplicates)
    const isDuplicate = captionCollection.timeWindow.textBuffer.some(item => 
      Math.abs(item.timestamp - timestampInSeconds) < 1 && 
      calculateSimilarity(item.text.toLowerCase(), currentText.toLowerCase()) > 0.8
    );
    
    if (!isDuplicate) {
      captionCollection.timeWindow.textBuffer.push({
        text: currentText,
        timestamp: timestampInSeconds,
        extractedTimestamp: extractedTimestamp
      });
      captionCollection.timeWindow.lastProcessedTime = timestampInSeconds;
      console.log(`üìù Added to window buffer (${captionCollection.timeWindow.textBuffer.length} items): ${currentText.substring(0, 30)}...`);
    } else {
      console.log('üö´ Skipped duplicate in time window:', currentText.substring(0, 30) + '...');
    }
  }

  function createSegmentFromTimeWindow(videoId, youtubeLink) {
    // ‚úÖ NEW: Create a single coherent segment from the time window
    if (captionCollection.timeWindow.textBuffer.length === 0) return;
    
    console.log('üîß Creating segment from time window with', captionCollection.timeWindow.textBuffer.length, 'items');
    
    // Sort by timestamp and combine text
    const sortedItems = captionCollection.timeWindow.textBuffer.sort((a, b) => a.timestamp - b.timestamp);
    const combinedText = sortedItems.map(item => item.text).join(' ');
    
    // Clean the combined text (minimal processing)
    const cleanedText = cleanAutoGeneratedText(combinedText);
    
    if (cleanedText.length > 8) {
      // Check for duplicates against existing segments
      const isDuplicate = captionCollection.segments.some(segment => {
        const timeOverlap = Math.abs(segment.start - sortedItems[0].timestamp) < 5;
        const textSimilarity = calculateSimilarity(segment.text.toLowerCase(), cleanedText.toLowerCase()) > 0.75;
        return timeOverlap && textSimilarity;
      });
      
      if (!isDuplicate) {
        // Collect video metadata
        const videoMetadata = collectVideoMetadata();
        
        // Create single segment from window
        const windowStartTime = sortedItems[0].timestamp;
        const windowEndTime = sortedItems[sortedItems.length - 1].timestamp + 2;
        
        captionCollection.segments.push({
          start: windowStartTime,
          end: windowEndTime,
          duration: windowEndTime - windowStartTime,
          text: cleanedText,
          timestamp: Date.now(),
          videoId: videoId,
          youtubeLink: youtubeLink ? youtubeLink.replace(/&t=\d+s/, `&t=${Math.floor(windowStartTime)}s`) : '#',
          originalTimestamp: sortedItems[0].extractedTimestamp,
          timeWindowSegment: true,
          itemCount: sortedItems.length,
          // Add video metadata
          videoTitle: videoMetadata.title,
          channelName: videoMetadata.channel,
          pageUrl: videoMetadata.url,
          // Chunk information
          chunkNumber: captionCollection.chunkCounter,
          isNewChunk: false
        });
        
        console.log(`‚úÖ Created time-window segment [${sortedItems[0].extractedTimestamp}]:`, cleanedText.substring(0, 60) + '...');
        console.log(`   üìä Window: ${sortedItems.length} items, ${Math.floor(windowEndTime - windowStartTime)}s duration`);
      } else {
        console.log('üö´ Skipped duplicate time-window segment:', cleanedText.substring(0, 40) + '...');
      }
    }
    
    // Clear the buffer
    captionCollection.timeWindow.textBuffer = [];
  }

  function processAutoGeneratedCaption(currentText, timestampInSeconds, extractedTimestamp, videoId, youtubeLink, isNewChunk) {
    // ‚úÖ Enhanced: Process auto-generated captions with aggressive cleaning
    console.log('ü§ñ Processing auto-generated caption:', currentText.substring(0, 40) + '...');
    
    // Pre-clean the input text before processing
    const preCleanedText = cleanAutoGeneratedText(currentText);
    
    // Extract new content from overlapping stream
    const newContent = extractNewContentFromStream(preCleanedText);
    
    if (newContent && newContent.length > 2) {
      // Add to stream buffer with additional cleaning
      const bufferAddition = cleanAutoGeneratedText(newContent);
      captionCollection.streamBuffer += (captionCollection.streamBuffer ? ' ' : '') + bufferAddition;
      captionCollection.lastProcessedText = preCleanedText;
      
      console.log('üìù Added to stream:', bufferAddition);
      console.log('üìö Current stream buffer:', captionCollection.streamBuffer.substring(0, 80) + '...');
      
      // Check if we should create a segment (on natural boundaries or chunk completion)
      if (shouldCreateSegment(captionCollection.streamBuffer, isNewChunk)) {
        // Apply extra aggressive cleaning for final segment
        const cleanedText = masterCleanAutoGeneratedSegment(captionCollection.streamBuffer);
        
        if (cleanedText.length > 8) {
          // Check for duplicates before creating segment
          const isDuplicate = captionCollection.segments.some(segment => {
            const timeOverlap = Math.abs(segment.start - (captionCollection.currentChunkStartTime || timestampInSeconds)) < 5;
            const textSimilarity = calculateSimilarity(segment.text.toLowerCase(), cleanedText.toLowerCase()) > 0.8;
            return timeOverlap && textSimilarity;
          });
          
          if (!isDuplicate) {
            // Collect video metadata for proper attribution
            const videoMetadata = collectVideoMetadata();
            
            // Create segment from accumulated stream
            captionCollection.segments.push({
            start: captionCollection.currentChunkStartTime || timestampInSeconds,
            end: timestampInSeconds + 3,
            duration: timestampInSeconds - (captionCollection.currentChunkStartTime || timestampInSeconds) + 3,
            text: cleanedText,
            timestamp: Date.now(),
            videoId: videoId,
            youtubeLink: youtubeLink,
            originalTimestamp: extractedTimestamp,
            autoGenerated: true,
            isNewChunk: isNewChunk,
            streamReconstructed: true,
            // Add video metadata for proper save tab display
            videoTitle: videoMetadata.title,
            channelName: videoMetadata.channel,
            pageUrl: videoMetadata.url
          });
          
            console.log('‚úÖ Created auto-generated segment:', cleanedText.substring(0, 50) + '...');
            
            // Reset buffer for next segment
            captionCollection.streamBuffer = '';
          } else {
            console.log('üö´ Skipped duplicate auto-generated segment:', cleanedText.substring(0, 30) + '...');
            // Still reset buffer even for duplicates
            captionCollection.streamBuffer = '';
          }
        }
      }
    }
  }

  function extractNewContentFromStream(currentText) {
    // Extract only new content by comparing with last processed text
    if (!captionCollection.lastProcessedText) {
      return currentText.trim(); // First caption
    }
    
    const lastText = captionCollection.lastProcessedText.toLowerCase().trim();
    const currentTextLower = currentText.toLowerCase().trim();
    
    // If texts are identical, return empty (no new content)
    if (lastText === currentTextLower) {
      return '';
    }
    
    // Find overlap between last and current
    const lastWords = lastText.split(/\s+/).filter(w => w.length > 0);
    const currentWords = currentTextLower.split(/\s+/).filter(w => w.length > 0);
    const originalCurrentWords = currentText.split(/\s+/).filter(w => w.length > 0);
    
    // Look for the longest matching suffix of last text with prefix of current
    let bestOverlapLength = 0;
    
    // Try progressively larger overlaps
    for (let overlapLen = 1; overlapLen <= Math.min(12, lastWords.length, currentWords.length); overlapLen++) {
      const lastSuffix = lastWords.slice(-overlapLen).join(' ');
      const currentPrefix = currentWords.slice(0, overlapLen).join(' ');
      
      if (lastSuffix === currentPrefix) {
        bestOverlapLength = overlapLen;
      }
    }
    
    // Also check for partial word matches (handle word splits like 'realmwhere')
    if (bestOverlapLength === 0 && lastWords.length > 0 && currentWords.length > 0) {
      const lastLastWord = lastWords[lastWords.length - 1];
      const firstCurrentWord = currentWords[0];
      
      // Check if current text starts with part of the last word
      if (firstCurrentWord.startsWith(lastLastWord) && firstCurrentWord.length > lastLastWord.length) {
        // Extract the continuation of the last word plus remaining words
        const completedWord = originalCurrentWords[0];
        const remainingWords = originalCurrentWords.slice(1);
        return [completedWord, ...remainingWords].join(' ').trim();
      }
      
      // Check if last word ends with part of first current word
      if (lastLastWord.includes(firstCurrentWord) && lastLastWord.length > firstCurrentWord.length) {
        // Skip the overlapping part
        bestOverlapLength = 1;
      }
    }
    
    // Return the non-overlapping part
    const newWords = originalCurrentWords.slice(bestOverlapLength);
    const newContent = newWords.join(' ').trim();
    
    // Clean up common issues
    const cleanedContent = newContent
      .replace(/\s+/g, ' ') // Normalize spaces
      .replace(/([a-z])([A-Z])/g, '$1 $2') // Add space between merged words
      .trim();
    
    if (cleanedContent !== currentText && cleanedContent.length > 0) {
      console.log('üîÑ Extracted new content:', cleanedContent, '(removed', bestOverlapLength, 'overlapping words)');
    }
    
    return cleanedContent;
  }

  function shouldCreateSegment(streamBuffer, isNewChunk) {
    // Decide when to create a segment from the stream buffer
    
    // Always create segment on new chunk
    if (isNewChunk) {
      console.log('üì¶ Creating segment due to new chunk');
      return true;
    }
    
    // Create segment at natural sentence boundaries
    if (streamBuffer.length > 30 && /[.!?]\s*$/.test(streamBuffer.trim())) {
      console.log('üìù Creating segment at sentence boundary');
      return true;
    }
    
    // Create segment at natural breaks (conjunctions, pauses)
    if (streamBuffer.length > 60) {
      const endsWithNaturalBreak = /\b(and|but|so|then|now|well|okay|right|because|however|therefore|meanwhile|also|furthermore)\s*$/i.test(streamBuffer.trim());
      if (endsWithNaturalBreak) {
        console.log('üìù Creating segment at natural break');
        return true;
      }
    }
    
    // Create segment if buffer gets too long (prevent memory issues and improve readability)
    if (streamBuffer.length > 150) {
      console.log('üìè Creating segment due to length limit');
      return true;
    }
    
    // Create segment if we have accumulated enough meaningful content
    const words = streamBuffer.trim().split(/\s+/);
    if (words.length >= 12 && streamBuffer.length > 80) {
      console.log('üìä Creating segment due to word count (', words.length, 'words)');
      return true;
    }
    
    return false;
  }

  function cleanAutoGeneratedText(text) {
    if (!text || text.length < 2) return '';
    
    console.log('üßΩ Minimal cleaning auto-generated text:', text.substring(0, 60) + '...');
    
    // SIMPLIFIED: Only fix essential contractions and normalize spaces
    let cleaned = text
      // Fix only the most common broken contractions
      .replace(/\bdo\s+n't\b/gi, "don't")
      .replace(/\byou\s+re\b/gi, "you're")
      .replace(/\bI\s+m\b/gi, "I'm")
      .replace(/\bI\s+ve\b/gi, "I've")
      .replace(/\bI\s+ll\b/gi, "I'll")
      .replace(/\bdoesn\s+t\b/gi, "doesn't")
      .replace(/\bit\s+s\b/gi, "it's")
      .replace(/\bthe\s+re\b/gi, "there")
      .replace(/\byou\s+ll\b/gi, "you'll")
      .replace(/\bwe\s+ve\b/gi, "we've")
      .replace(/\byou\s+ve\b/gi, "you've")
      .replace(/\bcan\s+t\b/gi, "can't")
      .replace(/\bwon\s+t\b/gi, "won't")
      .replace(/\bisn\s+t\b/gi, "isn't")
      .replace(/\bwasn\s+t\b/gi, "wasn't")
      .replace(/\baren\s+t\b/gi, "aren't")
      .replace(/\bweren\s+t\b/gi, "weren't")
      .replace(/\bhadn\s+t\b/gi, "hadn't")
      .replace(/\bhaven\s+t\b/gi, "haven't")
      .replace(/\bhasn\s+t\b/gi, "hasn't")
      .replace(/\bwouldn\s+t\b/gi, "wouldn't")
      .replace(/\bshouldn\s+t\b/gi, "shouldn't")
      .replace(/\bcouldn\s+t\b/gi, "couldn't")
      
      // Normalize whitespace only
      .replace(/\s+/g, ' ')
      .trim();
    
    if (cleaned !== text && cleaned.length > 5) {
      console.log('‚ú® Minimal cleaned result:', cleaned.substring(0, 60) + '...');
    }
    
    return cleaned;
  }

  function calculateSimilarity(text1, text2) {
    // Calculate text similarity using word overlap
    const words1 = text1.split(/\s+/).filter(w => w.length > 2);
    const words2 = text2.split(/\s+/).filter(w => w.length > 2);
    
    if (words1.length === 0 || words2.length === 0) return 0;
    
    const set1 = new Set(words1);
    const set2 = new Set(words2);
    const intersection = new Set([...set1].filter(w => set2.has(w)));
    
    return intersection.size / Math.max(set1.size, set2.size);
  }

  function removePhraseRepetitions(text) {
    // Enhanced phrase-level repetition removal
    const words = text.split(/\s+/);
    if (words.length < 4) return text;
    
    // Check for phrase repetitions of various lengths
    for (let phraseLen = 2; phraseLen <= Math.floor(words.length / 2); phraseLen++) {
      for (let i = 0; i <= words.length - phraseLen * 2; i++) {
        const phrase1 = words.slice(i, i + phraseLen).join(' ');
        const phrase2 = words.slice(i + phraseLen, i + phraseLen * 2).join(' ');
        
        if (phrase1.toLowerCase() === phrase2.toLowerCase()) {
          // Found repetition - remove the second occurrence
          const before = words.slice(0, i + phraseLen);
          const after = words.slice(i + phraseLen * 2);
          console.log('üóëÔ∏è Removed phrase repetition:', phrase1);
          return [...before, ...after].join(' ');
        }
      }
    }
    
    // Check for non-adjacent repetitions (like "every week...every week")
    for (let phraseLen = 3; phraseLen <= 8; phraseLen++) {
      for (let i = 0; i <= words.length - phraseLen; i++) {
        const phrase1 = words.slice(i, i + phraseLen).join(' ');
        
        // Look for this phrase later in the text
        for (let j = i + phraseLen + 1; j <= words.length - phraseLen; j++) {
          const phrase2 = words.slice(j, j + phraseLen).join(' ');
          
          if (phrase1.toLowerCase() === phrase2.toLowerCase()) {
            // Found non-adjacent repetition - remove the second occurrence
            const before = words.slice(0, j);
            const after = words.slice(j + phraseLen);
            console.log('üóëÔ∏è Removed non-adjacent repetition:', phrase1);
            return [...before, ...after].join(' ');
          }
        }
      }
    }
    
    return text;
  }

  function removeSentenceRepetitions(text) {
    // Remove sentence-level repetitions
    const sentences = text.split(/[.!?]+/).map(s => s.trim()).filter(s => s.length > 0);
    if (sentences.length < 2) return text;
    
    const unique = [];
    for (const sentence of sentences) {
      const isDuplicate = unique.some(existing => 
        sentence.toLowerCase() === existing.toLowerCase() ||
        (sentence.length > 10 && existing.includes(sentence.toLowerCase())) ||
        (existing.length > 10 && sentence.toLowerCase().includes(existing.toLowerCase()))
      );
      
      if (!isDuplicate) {
        unique.push(sentence);
      } else {
        console.log('üóëÔ∏è Removed sentence repetition:', sentence.substring(0, 30) + '...');
      }
    }
    
    return unique.join('. ') + (unique.length > 0 && !text.match(/[.!?]$/) ? '.' : '');
  }

  function masterCleanupSegments(segments) {
    // Master cleanup function for final processing
    console.log('üßπ Running master cleanup on', segments.length, 'segments');
    
    if (!segments || segments.length === 0) return [];
    
    // Step 1: Clean individual segments
    let cleaned = segments.map(segment => ({
      ...segment,
      text: cleanAutoGeneratedText(segment.text)
    })).filter(segment => segment.text && segment.text.length > 5);
    
    // Step 2: Remove duplicates based on text similarity
    const unique = [];
    for (const segment of cleaned) {
      const isDuplicate = unique.some(existing => 
        calculateSimilarity(segment.text.toLowerCase(), existing.text.toLowerCase()) > 0.85
      );
      if (!isDuplicate) {
        unique.push(segment);
      }
    }
    
    // Step 3: Merge very short segments with adjacent ones
    const merged = [];
    for (let i = 0; i < unique.length; i++) {
      const current = unique[i];
      const next = unique[i + 1];
      
      if (current.text.split(' ').length <= 3 && next && 
          Math.abs(next.start - current.end) < 5) {
        // Merge short segment with next
        merged.push({
          ...current,
          text: current.text + ' ' + next.text,
          end: next.end,
          duration: next.end - current.start
        });
        i++; // Skip next since we merged it
      } else {
        merged.push(current);
      }
    }
    
    console.log(`üìä Master cleanup: ${segments.length} ‚Üí ${cleaned.length} ‚Üí ${unique.length} ‚Üí ${merged.length}`);
    return merged;
  }

  function masterCleanAutoGeneratedSegment(text) {
    // SIMPLIFIED: Basic cleaning only to prevent over-processing
    console.log('üßΩ Basic cleaning segment:', text.substring(0, 50) + '...');
    
    if (!text || text.length < 3) return '';
    
    // Just use the basic clean function - no multiple passes
    const cleaned = cleanAutoGeneratedText(text);
    
    if (cleaned !== text) {
      console.log('‚ú® Basic clean result:', cleaned.substring(0, 50) + '...');
    }
    
    return cleaned;
  }

  function removeAdvancedRepetitions(text) {
    // More advanced repetition removal
    let words = text.split(/\s+/);
    
    // First pass: Remove exact phrase repetitions like "every week every week"
    for (let len = 1; len <= 6; len++) {
      let i = 0;
      while (i <= words.length - len * 2) {
        const pattern1 = words.slice(i, i + len).join(' ');
        const pattern2 = words.slice(i + len, i + len * 2).join(' ');
        
        if (pattern1.toLowerCase() === pattern2.toLowerCase() && pattern1.trim().length > 0) {
          words.splice(i + len, len); // Remove the duplicate
          console.log('üóëÔ∏è Removed exact repetition:', pattern1);
          // Don't increment i, check the same position again
        } else {
          i++;
        }
      }
    }
    
    // Second pass: Remove cascading repetitions within the text
    let cleanText = words.join(' ');
    
    // Handle specific patterns from user examples
    cleanText = cleanText
      .replace(/\b(every\s+week)\s+\1\b/gi, '$1')
      .replace(/\b(meaningful\s+revenue)\s+\1\b/gi, '$1')
      .replace(/\b(have\s+smaller)\s+\1\b/gi, '$1')
      .replace(/\b(value\s+density)\s+\1\b/gi, '$1')
      .replace(/\b(\w+)\s+\1\s+\1\b/gi, '$1') // Triple repetitions
      .replace(/\b(\w+\s+\w+)\s+\1\b/gi, '$1') // Phrase repetitions
      .replace(/\b(\w+)\s+\1\b/gi, '$1') // Single word repetitions
      // Clean up fragments like "on. on."
      .replace(/\b(\w+)\.?\s+\1\.?\b/gi, '$1')
      // Clean incomplete fragments like "who who", "where it's like come you"
      .replace(/\b(who|what|where|when|how)\s+\1\b/gi, '$1')
      .replace(/\bcome\s+you\b/gi, 'come on')
      .replace(/\blike\s+come\s+you\b/gi, 'like, you know')
      // Remove trailing incomplete words
      .replace(/\s+(on\.?\s*)+$/gi, '')
      .replace(/\s+(you\.?\s*)+$/gi, '')
      .trim();
    
    return cleanText;
  }

  function cleanFragments(text) {
    // Clean up common fragment patterns with enhanced detection
    return text
      .replace(/\b(\w+)\s+\1\s*$/g, '$1') // Remove end repetitions
      .replace(/^(\w+)\s+\1\b/g, '$1') // Remove start repetitions
      .replace(/\b(\w+)\.\s*\1\.?/g, '$1.') // Fix "word. word." -> "word."
      .replace(/\b(by|who|what|how|when|where)\s+\1\b/gi, '$1') // Remove question word repetitions
      // Enhanced fragment cleanup for user-reported issues
      .replace(/\bwhere\s+it's\s+like\s+come\s+you\b/gi, 'where it comes from')
      .replace(/\bon\.\s*on\.\s*/gi, 'on. ')
      .replace(/\bwho\s+who\b/gi, 'who')
      .replace(/\bthe\s+the\b/gi, 'the')
      .replace(/\band\s+and\b/gi, 'and')
      .replace(/\bof\s+of\b/gi, 'of')
      .replace(/\bin\s+in\b/gi, 'in')
      .replace(/\bto\s+to\b/gi, 'to')
      .replace(/\bis\s+is\b/gi, 'is')
      .replace(/\bwith\s+with\b/gi, 'with')
      // Clean up split contractions and incomplete words
      .replace(/\bi\s+m\b/gi, "I'm")
      .replace(/\byou\s+re\b/gi, "you're")
      .replace(/\bwe\s+re\b/gi, "we're")
      .replace(/\bthey\s+re\b/gi, "they're")
      .replace(/\bdon\s+t\b/gi, "don't")
      .replace(/\bcan\s+t\b/gi, "can't")
      .replace(/\bwon\s+t\b/gi, "won't")
      .replace(/\bisn\s+t\b/gi, "isn't")
      .replace(/\baren\s+t\b/gi, "aren't")
      .replace(/\bwasn\s+t\b/gi, "wasn't")
      .replace(/\bweren\s+t\b/gi, "weren't")
      .replace(/\bhasn\s+t\b/gi, "hasn't")
      .replace(/\bhaven\s+t\b/gi, "haven't")
      .replace(/\bhadn\s+t\b/gi, "hadn't")
      // Clean trailing/leading fragments
      .replace(/\s+(\w+)\s*$/, ' $1') // Clean trailing spaces
      .replace(/^(\w+)\s+/, '$1 ') // Clean leading spaces
      .replace(/^\w\s+/, '') // Remove single letters at start
      .replace(/\s+\w$/, '') // Remove single letters at end
      .trim();
  }

  function finalPolish(text) {
    // Final polishing pass
    return text
      .replace(/\s+/g, ' ') // Final space normalization
      .replace(/\s*([.!?])\s*/g, '$1 ') // Fix punctuation spacing
      .replace(/([.!?])\s*$/, '$1') // Clean end punctuation
      .replace(/^\s*(.+?)\s*$/, '$1') // Trim
      // Ensure proper capitalization
      .replace(/^./, str => str.toUpperCase())
      // Add period if needed
      .replace(/^(.{15,}[^.!?])$/, '$1.');
  }

  function startCaptionCollection(chunkDuration = 45) {
    if (captionCollection.isCollecting) {
      console.log('üì° HYBRID Caption collection already in progress');
      return;
    }
    
    console.log(`üöÄ HYBRID Starting real-time caption collection with ${chunkDuration}s chunks...`);
    captionCollection.isCollecting = true;
    captionCollection.startTime = Date.now();
    
    // ‚úÖ FIX: Don't reset segments - keep accumulating from previous collections
    // captionCollection.segments = []; // ‚ùå This was resetting all previous collections!
    console.log(`üìä CONTINUING COLLECTION: ${captionCollection.segments.length} existing segments`);
    
    captionCollection.lastCaptionTime = 0;
    captionCollection.lastCaptionText = ''; // Track last text to avoid duplicates
    
    // ‚úÖ NEW: Set chunk duration from UI
    captionCollection.chunkDurationThreshold = chunkDuration;
    
    // ‚úÖ NEW: Initialize chunk tracking for automatic chunking
    const player = document.querySelector('#movie_player');
    if (player && player.getCurrentTime) {
      captionCollection.currentChunkStartTime = player.getCurrentTime();
      const mins = Math.floor(captionCollection.currentChunkStartTime / 60);
      const secs = Math.floor(captionCollection.currentChunkStartTime % 60);
      captionCollection.currentChunkStartTimestamp = `${mins}:${secs.toString().padStart(2, '0')}`;
    }
    captionCollection.chunkCounter = 0;
    captionCollection.lastCollectedTimestamp = captionCollection.currentChunkStartTime;
    
    // ‚úÖ DEBUG: Log initialization values
    console.log('üöÄ COLLECTION INITIALIZED:', {
      startTime: captionCollection.currentChunkStartTime,
      lastCollectedTimestamp: captionCollection.lastCollectedTimestamp,
      timeSegmentThreshold: captionCollection.timeSegmentThreshold,
      chunkDurationThreshold: captionCollection.chunkDurationThreshold
    });
    
    // Enable captions if needed with better detection
    const ccButton = document.querySelector('.ytp-subtitles-button, .ytp-menuitem[aria-label*="Captions"], button[aria-label*="Captions"]');
    if (ccButton && ccButton.getAttribute('aria-pressed') !== 'true') {
      console.log('üîò HYBRID Enabling captions...');
      ccButton.click();
      
      // Wait for captions to load
      setTimeout(() => {
        const captionCheck = document.querySelectorAll('.ytp-caption-segment, .captions-text, .caption-visual-line, .ytp-caption-window-container span');
        console.log('üì∫ HYBRID Caption elements after enabling:', captionCheck.length);
      }, 2000);
    }
    
    // Start monitoring with enhanced selectors
    captionCollection.interval = setInterval(() => {
      // More focused caption selectors to avoid UI noise
      const allCaptionElements = document.querySelectorAll(`
        .ytp-caption-segment, 
        .captions-text, 
        .caption-visual-line
      `);
      
      // Filter out UI elements
      const captionElements = Array.from(allCaptionElements).filter(el => {
        // Skip elements that are clearly UI controls
        if (el.closest('.ytp-chrome-controls') || 
            el.closest('.ytp-settings-menu') ||
            el.closest('.ytp-popup') ||
            el.closest('.ytp-menuitem') ||
            el.closest('.ytp-tooltip') ||
            el.closest('.ytp-panel')) {
          return false;
        }
        
        const text = el.textContent?.trim() || '';
        // Skip UI text patterns
        if (text.includes('Èü≥Ëªå') || 
            text.includes('Â≠óÂπï') ||
            text.includes('Ëá™Âãï') ||
            text.includes('1080p') ||
            text.includes('HD') ||
            text.includes('Ë≥áË®ä') ||
            text.includes('Ë≥ºÁâ©') ||
            text.includes('Âêë‰∏äÊãâÂç≥ÂèØË∑≥ËΩâ') ||
            text.match(/^\d+:\d+\s*\/\s*\d+:\d+$/) ||
            text.match(/^\(\d+\)$/)) {
          return false;
        }
        
        return text.length > 5; // Only meaningful text
      });
      
      // Debug logging every 5 seconds
      if (Date.now() % 5000 < 1000) {
        console.log('üîç HYBRID Caption status:', {
          elementsFound: captionElements.length,
          ccButtonPressed: document.querySelector('.ytp-subtitles-button')?.getAttribute('aria-pressed'),
          collecting: captionCollection.isCollecting,
          segmentsCollected: captionCollection.segments.length,
          videoPlaying: !document.querySelector('#movie_player')?.paused
        });
        
        if (captionElements.length > 0) {
          const rawText = Array.from(captionElements).map(el => el.textContent?.trim()).join(' ').substring(0, 100);
          const cleanedPreview = rawText
            .replace(/Ë≥áË®ä\s*Ë≥ºÁâ©\s*/g, '')
            .replace(/Âêë‰∏äÊãâÂç≥ÂèØË∑≥ËΩâËá≥Á≤æÁ¢∫ÁöÑÊôÇÈñìÈªû/g, '')
            .replace(/Turning the Outline Into a Presentation \(Quick & Dirty\).*?‚Ä¢/g, '')
            .replace(/\d{1,2}:\d{2}\s*‚Ä¢/g, '')
            .trim().substring(0, 80);
          console.log('üì∫ Raw caption text:', rawText);
          console.log('üßπ Cleaned preview:', cleanedPreview);
        }
      }
      
      if (captionElements.length > 0) {
        const player = document.querySelector('#movie_player');
        const currentTime = player && player.getCurrentTime ? player.getCurrentTime() : 0;
        
        // Get text from caption elements with better filtering
        let currentText = Array.from(captionElements)
          .map(el => el.textContent?.trim())
          .filter(text => text && text.length > 3) // Filter out very short text
          .join(' ');
        
        // Enhanced cleaning for better learning experience
        currentText = currentText
          .replace(/Ë≥áË®ä\s*Ë≥ºÁâ©\s*/g, '') // Remove "Info Shopping" 
          .replace(/Âêë‰∏äÊãâÂç≥ÂèØË∑≥ËΩâËá≥Á≤æÁ¢∫ÁöÑÊôÇÈñìÈªû/g, '') // Remove swipe instruction
          .replace(/dictate\.\s*Whoops\./g, '') // Remove "dictate. Whoops."
          .replace(/^\s*‚Ä¢\s*/, '') // Remove bullet points at start
          .replace(/Èü≥Ëªå\s*\(\d+\)/g, '') // Remove track info
          .replace(/Â≠óÂπï\s*\(\d+\)/g, '') // Remove subtitle info  
          .replace(/Ëá™Âãï\s*\(.*?\)/g, '') // Remove auto info
          .replace(/\d+p\s*HD/g, '') // Remove quality info
          .replace(/\d+:\d+\s*\/\s*\d+:\d+/g, '') // Remove time progress
          .replace(/ËßÄÁúãÂÆåÊï¥ÂΩ±.*?/g, '') // Remove view full video text
          .replace(/\(\d+\)/g, '') // Remove number indicators
          .replace(/\s+/g, ' ') // Normalize whitespace
          .trim();
        
        // Extract and preserve any embedded timestamps for learning purposes
        const timestampMatches = currentText.match(/\d{1,2}:\d{2}/g);
        let extractedTimestamp = null;
        let timestampInSeconds = currentTime;
        
        if (timestampMatches && timestampMatches.length > 0) {
          // Use the first timestamp found as reference
          extractedTimestamp = timestampMatches[0];
          const [minutes, seconds] = extractedTimestamp.split(':').map(Number);
          timestampInSeconds = (minutes * 60) + seconds;
          console.log('üìå Found embedded timestamp for learning:', extractedTimestamp, '‚Üí', timestampInSeconds, 'seconds');
        } else {
          // ‚úÖ FIX: Enhanced current time detection with multiple methods
          const player = document.querySelector('#movie_player');
          let currentVideoTime = currentTime; // Use the currentTime from outer scope
          
          // Try multiple methods to get current video time
          if (player) {
            if (typeof player.getCurrentTime === 'function') {
              try {
                currentVideoTime = player.getCurrentTime();
              } catch (e) {
                console.log('‚ùå player.getCurrentTime failed:', e.message);
              }
            }
            
            // Fallback: try video element directly
            if (!currentVideoTime || currentVideoTime === 0) {
              const video = player.querySelector('video');
              if (video && typeof video.currentTime === 'number') {
                currentVideoTime = video.currentTime;
              }
            }
          }
          
          // ‚úÖ FIX: Always ensure we have a valid timestamp
          timestampInSeconds = currentVideoTime || 0;
          const mins = Math.floor(timestampInSeconds / 60);
          const secs = Math.floor(timestampInSeconds % 60);
          extractedTimestamp = `${mins}:${secs.toString().padStart(2, '0')}`;
          
          console.log('üïê Using video time:', extractedTimestamp, '(', timestampInSeconds, 'seconds)');
        }
        
        // ‚úÖ FIX: Enhanced text filtering to prevent repetitive content
        if (currentText && 
            currentText.length > 15 && // Slightly lower threshold for learning content
            currentText !== captionCollection.lastCaptionText) {
          
          // ‚úÖ FIX: More aggressive deduplication - check last 5 segments with lower threshold
          const isUnique = captionCollection.segments.length === 0 || 
            !captionCollection.segments.slice(-5).some(segment => {
              const similarity = calculateTextSimilarity(currentText.toLowerCase(), segment.text.toLowerCase());
              return similarity > 0.7; // ‚úÖ Lower threshold - reject more similar content
            });
          
          // ‚úÖ FIX: Additional check - reject if text is mostly contained in recent segments
          const isNotSubstring = captionCollection.segments.length === 0 ||
            !captionCollection.segments.slice(-3).some(segment => {
              const segText = segment.text.toLowerCase();
              const currText = currentText.toLowerCase();
              return segText.includes(currText) || currText.includes(segText);
            });
          
          if (isUnique && isNotSubstring) {
            // ‚úÖ FIX: Enhanced time gap detection for proper segment creation
            const timeGap = Math.abs(timestampInSeconds - captionCollection.lastCollectedTimestamp);
            const isSignificantTimeGap = timeGap > captionCollection.timeSegmentThreshold;
            
            // ‚úÖ FIX: Additional check - if user jumped backwards or forwards significantly
            const isUserJump = timeGap > 5 && captionCollection.segments.length > 0; // Any gap > 5s is likely a user jump
            
            // ‚úÖ DEBUG: Enhanced logging for time gap detection
            if (captionCollection.segments.length > 0) {
              console.log(`‚è±Ô∏è TIME GAP CHECK: Current=${timestampInSeconds.toFixed(1)}s, Last=${captionCollection.lastCollectedTimestamp.toFixed(1)}s, Gap=${timeGap.toFixed(1)}s, Threshold=${captionCollection.timeSegmentThreshold}s`);
              console.log(`üîç Gap Analysis: isSignificant=${isSignificantTimeGap}, isUserJump=${isUserJump}, willCreateSegment=${isSignificantTimeGap || isUserJump}`);
            }
            
            // ‚úÖ FIX: Better chunk duration calculation - prevent division issues and improve logic
            let chunkDuration = 0;
            let isNewChunk = false;
            
            if (captionCollection.currentChunkStartTime !== undefined && 
                !isNaN(captionCollection.currentChunkStartTime) && 
                !isNaN(timestampInSeconds)) {
              chunkDuration = Math.abs(timestampInSeconds - captionCollection.currentChunkStartTime);
              
              // ‚úÖ Enhanced chunking logic for auto-generated captions
              const effectiveChunkThreshold = captionCollection.autoGenerated ? 
                Math.max(captionCollection.chunkDurationThreshold, 25) : // Min 25s for auto-generated
                captionCollection.chunkDurationThreshold;
              
              isNewChunk = chunkDuration > effectiveChunkThreshold && 
                          captionCollection.segments.length > 0 && 
                          !isSignificantTimeGap; // Don't create chunk if already creating new segment
              
              // Force new chunk if auto-generated stream buffer is getting too full
              if (captionCollection.autoGenerated && 
                  captionCollection.streamBuffer && 
                  captionCollection.streamBuffer.length > 250) {
                console.log('üîÑ Forcing new chunk due to full stream buffer');
                isNewChunk = true;
              }
            }
            
            // ‚úÖ FIX: Create new segment when user jumps to different section
            if ((isSignificantTimeGap || isUserJump) && captionCollection.segments.length > 0) {
              const lastTime = Math.floor(captionCollection.lastCollectedTimestamp);
              const lastMins = Math.floor(lastTime / 60);
              const lastSecs = lastTime % 60;
              const lastTimeStr = `${lastMins}:${lastSecs.toString().padStart(2, '0')}`;
              console.log(`üïê USER JUMP detected: ${Math.floor(timeGap)}s gap (${lastTimeStr} ‚Üí ${extractedTimestamp}) - Creating new segment group`);
              
              // Mark this as start of new time segment group
              captionCollection.chunkCounter = 0;
              captionCollection.currentChunkStartTime = timestampInSeconds;
              captionCollection.currentChunkStartTimestamp = extractedTimestamp;
              
            } else if (isNewChunk && chunkDuration > 0) {
              const thresholdUsed = captionCollection.autoGenerated ? 
                Math.max(captionCollection.chunkDurationThreshold, 25) :
                captionCollection.chunkDurationThreshold;
              console.log(`üì¶ AUTO-CHUNK: Duration ${Math.floor(chunkDuration)}s exceeded threshold ${thresholdUsed}s - Creating new chunk at ${extractedTimestamp}`);
              if (captionCollection.autoGenerated) {
                console.log('ü§ñ Auto-generated caption chunk created with enhanced processing');
              }
              captionCollection.chunkCounter++;
              captionCollection.currentChunkStartTime = timestampInSeconds;
              captionCollection.currentChunkStartTimestamp = extractedTimestamp;
            }
            
            // Get current video info for creating YouTube links
            const videoId = extractVideoId();
            console.log('üÜî Video ID extracted:', videoId, 'from URL:', window.location.href);
            const youtubeLink = videoId ? `https://www.youtube.com/watch?v=${videoId}&t=${Math.floor(timestampInSeconds)}s` : '#';
            console.log('üîó Generated YouTube link:', youtubeLink);
            
            // ‚úÖ NEW: Use time-window collection approach for both auto and manual captions
            processTimeWindowCaption(currentText, timestampInSeconds, extractedTimestamp, videoId, youtubeLink, isNewChunk);
            
            captionCollection.lastCaptionTime = timestampInSeconds;
            captionCollection.lastCaptionText = currentText;
            captionCollection.lastCollectedTimestamp = timestampInSeconds;
            
            console.log(`‚úÖ HYBRID Collected [${extractedTimestamp}]:`, currentText.substring(0, 50) + '...');
            if (isSignificantTimeGap || isUserJump) {
              console.log(`  üéØ NEW SEGMENT: Time gap ${Math.floor(timeGap)}s ‚Üí ${extractedTimestamp}`);
            }
            if (isNewChunk) {
              console.log(`  üì¶ NEW CHUNK #${captionCollection.chunkCounter}: ${extractedTimestamp}`);
            }
            console.log(`  üìä Total segments: ${captionCollection.segments.length}`);
          } else {
            // ‚úÖ FIX: Better logging for rejected content
            if (!isUnique) {
              console.log('üö´ HYBRID Rejected (too similar):', currentText.substring(0, 30) + '...');
            } else if (!isNotSubstring) {
              console.log('üö´ HYBRID Rejected (substring):', currentText.substring(0, 30) + '...');
            }
          }
        } else {
          // Debug why text was rejected
          if (!currentText) {
            console.log('‚ùå HYBRID No text after cleaning');
          } else if (currentText.length <= 10) {
            console.log('‚ùå HYBRID Text too short after cleaning:', currentText.length, 'chars:', currentText);
          } else if (currentText === captionCollection.lastCaptionText) {
            console.log('‚ùå HYBRID Same text as before:', currentText.substring(0, 30));
          }
        }
      }
    }, 1000); // Check every second
  }

  function stopCaptionCollection() {
    if (!captionCollection.isCollecting) {
      return { segments: [], duration: 0 };
    }
    
    console.log('üõë HYBRID Stopping caption collection...');
    captionCollection.isCollecting = false;
    
    // ‚úÖ NEW: Process any remaining time window buffer before stopping
    if (captionCollection.timeWindow.textBuffer.length > 0) {
      console.log('üì¶ Processing remaining time window buffer before stopping...');
      createSegmentFromTimeWindow(extractVideoId(), null);
    }
    
    if (captionCollection.interval) {
      clearInterval(captionCollection.interval);
      captionCollection.interval = null;
    }
    
    // Reset time window
    captionCollection.timeWindow.startTime = null;
    captionCollection.timeWindow.endTime = null;
    captionCollection.timeWindow.textBuffer = [];
    captionCollection.timeWindow.lastProcessedTime = 0;
    
    const duration = (Date.now() - captionCollection.startTime) / 1000;
    let segments = [...captionCollection.segments];
    
    console.log(`‚úÖ HYBRID Collection complete: ${segments.length} segments in ${duration}s`);
    
    // Apply master cleanup for auto-generated captions
    if (captionCollection.autoGenerated && segments.length > 0) {
      console.log('ü§ñ Applying master cleanup for auto-generated captions');
      segments = masterCleanupSegments(segments);
    }
    
    return { segments, duration };
  }

  async function downloadCompleteTranscript(videoId) {
    console.log('üì• HYBRID Attempting direct transcript download for:', videoId);
    
    try {
      // Method 1: Try to get caption tracks from page data
      const captionTracks = await getYouTubeCaptionTracks();
      console.log('üîç Caption tracks search result:', captionTracks);
      
      if (captionTracks && captionTracks.length > 0) {
        console.log('üéØ Found', captionTracks.length, 'caption tracks:', captionTracks.map(t => ({
          language: t.languageCode,
          name: t.name?.simpleText,
          isAsr: t.vssId?.includes('.asr')
        })));
        
        // Try each track until we get a complete transcript
        for (const track of captionTracks) {
          const transcript = await downloadFromCaptionTrack(track);
          if (transcript && transcript.length > 0) {
            console.log('‚úÖ Downloaded complete transcript from track:', track.languageCode);
            return transcript;
          }
        }
        console.log('‚ùå All caption tracks failed to download');
      } else {
        console.log('‚ùå No caption tracks found in page data');
      }

      // Method 2: Try YouTube's timedtext API directly
      console.log('üîÑ Trying timedtext API...');
      const timedTextTranscript = await tryTimedTextAPI(videoId);
      if (timedTextTranscript && timedTextTranscript.length > 0) {
        console.log('‚úÖ Downloaded via timedtext API');
        return timedTextTranscript;
      } else {
        console.log('‚ùå Timedtext API failed');
      }

      // Method 3: Don't fall back to metadata immediately - return null instead
      console.log('‚ùå All direct download methods failed');
      return null;
      
    } catch (error) {
      console.error('‚ùå Direct download failed:', error);
      return null;
    }
  }

  async function getYouTubeCaptionTracks() {
    // Try multiple sources for caption track information
    const sources = [
      () => window.ytInitialPlayerResponse?.captions?.playerCaptionsTracklistRenderer?.captionTracks,
      () => window.ytplayer?.config?.args?.player_response && JSON.parse(window.ytplayer.config.args.player_response)?.captions?.playerCaptionsTracklistRenderer?.captionTracks,
      () => {
        // Search in page scripts
        const scripts = document.querySelectorAll('script');
        for (const script of scripts) {
          if (script.textContent?.includes('captionTracks')) {
            const match = script.textContent.match(/"captionTracks":\s*(\[[^\]]*\])/);
            if (match) {
              try {
                return JSON.parse(match[1]);
              } catch (e) {
                continue;
              }
            }
          }
        }
        return null;
      }
    ];

    for (const getSource of sources) {
      try {
        const tracks = getSource();
        if (tracks && tracks.length > 0) {
          // Prioritize auto-generated tracks as they're more likely to be complete
          return tracks.sort((a, b) => {
            if (a.vssId?.includes('.asr') && !b.vssId?.includes('.asr')) return -1;
            if (!a.vssId?.includes('.asr') && b.vssId?.includes('.asr')) return 1;
            return 0;
          });
        }
      } catch (e) {
        continue;
      }
    }

    return null;
  }

  async function downloadFromCaptionTrack(track) {
    if (!track.baseUrl) return null;

    console.log('üì° Downloading from track:', track.name?.simpleText || track.languageCode);

    try {
      // Try different URL formats
      const urls = [
        track.baseUrl,
        track.baseUrl + '&fmt=srv3',
        track.baseUrl + '&fmt=json3',
        track.baseUrl + '&fmt=vtt',
        track.baseUrl.replace(/&caps=.*?(&|$)/, '$1'),
        track.baseUrl + '&tlang=en' // Try with translation
      ];

      for (const url of urls) {
        try {
          console.log('üåê Trying URL format...');
          const response = await fetch(url, {
            credentials: 'same-origin',
            headers: {
              'Accept': 'application/xml, text/xml, text/plain, application/json'
            }
          });

          if (response.ok) {
            const content = await response.text();
            if (content && content.trim().length > 100) { // Must be substantial content
              console.log('‚úÖ Got substantial response:', content.length, 'characters');
              
              // Try to parse as XML first
              const xmlTranscript = parseXMLTranscript(content);
              if (xmlTranscript && xmlTranscript.length > 0) {
                return xmlTranscript;
              }

              // Try to parse as JSON
              try {
                const jsonData = JSON.parse(content);
                const jsonTranscript = parseJSONTranscript(jsonData);
                if (jsonTranscript && jsonTranscript.length > 0) {
                  return jsonTranscript;
                }
              } catch (e) {
                // Not JSON, continue
              }

              // Try to parse as VTT
              const vttTranscript = parseVTTTranscript(content);
              if (vttTranscript && vttTranscript.length > 0) {
                return vttTranscript;
              }
            }
          }
        } catch (e) {
          console.log('‚ùå URL failed:', e.message);
          continue;
        }
      }
    } catch (error) {
      console.error('‚ùå Track download failed:', error);
    }

    return null;
  }

  function parseXMLTranscript(xmlContent) {
    try {
      const parser = new DOMParser();
      const doc = parser.parseFromString(xmlContent, 'text/xml');
      
      if (doc.querySelector('parsererror')) {
        return null;
      }

      const textElements = doc.querySelectorAll('text');
      if (textElements.length === 0) return null;

      const transcript = [];
      textElements.forEach(element => {
        const start = parseFloat(element.getAttribute('start') || '0');
        const duration = parseFloat(element.getAttribute('dur') || '3');
        const text = element.textContent
          ?.replace(/&amp;/g, '&')
          ?.replace(/&lt;/g, '<')
          ?.replace(/&gt;/g, '>')
          ?.replace(/&#39;/g, "'")
          ?.replace(/&quot;/g, '"')
          ?.trim();

        if (text && text.length > 0) {
          transcript.push({
            start: start,
            end: start + duration,
            duration: duration,
            text: text
          });
        }
      });

      return transcript.length > 0 ? transcript : null;
    } catch (error) {
      console.error('‚ùå XML parsing failed:', error);
      return null;
    }
  }

  function parseJSONTranscript(jsonData) {
    try {
      if (jsonData.events) {
        const transcript = [];
        jsonData.events.forEach(event => {
          if (event.segs) {
            let eventText = '';
            event.segs.forEach(seg => {
              if (seg.utf8) {
                eventText += seg.utf8;
              }
            });
            
            if (eventText.trim()) {
              transcript.push({
                start: (event.tStartMs || 0) / 1000,
                end: ((event.tStartMs || 0) + (event.dDurationMs || 3000)) / 1000,
                duration: (event.dDurationMs || 3000) / 1000,
                text: eventText.trim()
              });
            }
          }
        });
        return transcript.length > 0 ? transcript : null;
      }
      return null;
    } catch (error) {
      console.error('‚ùå JSON parsing failed:', error);
      return null;
    }
  }

  function parseVTTTranscript(vttContent) {
    try {
      const lines = vttContent.split('\n');
      const transcript = [];
      let currentEntry = null;

      for (let i = 0; i < lines.length; i++) {
        const line = lines[i].trim();
        
        // Time format: 00:00:00.000 --> 00:00:03.000
        const timeMatch = line.match(/(\d{2}:\d{2}:\d{2}\.\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}\.\d{3})/);
        if (timeMatch) {
          if (currentEntry && currentEntry.text) {
            transcript.push(currentEntry);
          }
          
          currentEntry = {
            start: timeToSeconds(timeMatch[1]),
            end: timeToSeconds(timeMatch[2]),
            duration: timeToSeconds(timeMatch[2]) - timeToSeconds(timeMatch[1]),
            text: ''
          };
        } else if (currentEntry && line && !line.includes('WEBVTT') && !line.match(/^\d+$/)) {
          currentEntry.text += (currentEntry.text ? ' ' : '') + line;
        }
      }

      if (currentEntry && currentEntry.text) {
        transcript.push(currentEntry);
      }

      return transcript.length > 0 ? transcript : null;
    } catch (error) {
      console.error('‚ùå VTT parsing failed:', error);
      return null;
    }
  }

  function timeToSeconds(timeString) {
    const parts = timeString.split(':');
    const seconds = parts[2].split('.');
    return parseInt(parts[0]) * 3600 + parseInt(parts[1]) * 60 + parseInt(seconds[0]) + parseInt(seconds[1]) / 1000;
  }

  async function tryTimedTextAPI(videoId) {
    console.log('‚ö° Trying timedtext API for:', videoId);
    
    const apiUrls = [
      `https://www.youtube.com/api/timedtext?v=${videoId}&lang=en&fmt=srv3`,
      `https://www.youtube.com/api/timedtext?v=${videoId}&lang=en&fmt=json3`,
      `https://www.youtube.com/api/timedtext?v=${videoId}&fmt=srv3`,
      `https://www.youtube.com/api/timedtext?v=${videoId}&fmt=json3`
    ];

    for (const url of apiUrls) {
      try {
        const response = await fetch(url, {
          credentials: 'same-origin'
        });
        
        if (response.ok) {
          const content = await response.text();
          if (content && content.trim().length > 50) {
            const transcript = parseXMLTranscript(content) || parseJSONTranscript(JSON.parse(content));
            if (transcript && transcript.length > 0) {
              return transcript;
            }
          }
        }
      } catch (e) {
        continue;
      }
    }

    return null;
  }

  async function tryVideoMetadata() {
    console.log('üìã Extracting from video metadata...');
    
    // This is a fallback - not really a transcript but better than nothing
    const title = document.querySelector('h1.ytd-video-primary-info-renderer')?.textContent?.trim();
    const description = document.querySelector('#description')?.textContent?.trim()?.substring(0, 500);
    
    if (title || description) {
      return [{
        start: 0,
        end: 30,
        duration: 30,
        text: `Video: ${title || 'Untitled'}. ${description ? 'Description: ' + description : ''} (Note: This is metadata, not actual captions. The video may not have completed auto-captions yet.)`
      }];
    }

    return null;
  }

  async function tryAlternativeTranscriptMethods(videoId) {
    console.log('üîÑ Trying alternative methods...');
    
    // Try to wait for auto-captions to be processed and then get them
    return new Promise((resolve) => {
      setTimeout(async () => {
        try {
          // Try one more time to get current captions after waiting
          const transcript = await getCurrentCaptions();
          resolve(transcript);
        } catch (e) {
          resolve(null);
        }
      }, 3000);
    });
  }

  function parseTimestamp(timestamp) {
    const parts = timestamp.trim().split(':').map(p => parseInt(p, 10));
    if (parts.length === 3) {
      return parts[0] * 3600 + parts[1] * 60 + parts[2];
    } else if (parts.length === 2) {
      return parts[0] * 60 + parts[1];
    }
    return parts[0] || 0;
  }

  function isNewMeaningfulContent(newText, existingSegments) {
    // Basic length check
    if (!newText || newText.length < 10) return false;
    
    // Check against recent segments (last 5)
    const recentSegments = existingSegments.slice(-5);
    
    for (const segment of recentSegments) {
      const existingText = segment.text.toLowerCase();
      const currentText = newText.toLowerCase();
      
      // Skip if too similar to existing content
      if (calculateTextSimilarity(currentText, existingText) > 0.7) {
        return false;
      }
      
      // Skip if current text is contained in existing or vice versa
      if (existingText.includes(currentText) || currentText.includes(existingText)) {
        return false;
      }
    }
    
    // Check for repetitive patterns within the text itself
    const words = newText.split(' ');
    const uniqueWords = new Set(words.map(w => w.toLowerCase()));
    
    // Require good word diversity (at least 60% unique words)
    const wordDiversity = uniqueWords.size / words.length;
    if (wordDiversity < 0.6) {
      return false;
    }
    
    // Check for obvious repetition patterns
    const hasRepetitivePattern = /(.{10,})\1/.test(newText.toLowerCase());
    if (hasRepetitivePattern) {
      return false;
    }
    
    return true;
  }

  function calculateTextSimilarity(text1, text2) {
    const words1 = new Set(text1.split(' '));
    const words2 = new Set(text2.split(' '));
    
    const intersection = new Set([...words1].filter(x => words2.has(x)));
    const union = new Set([...words1, ...words2]);
    
    return intersection.size / union.size;
  }

  async function forceCollectionSample() {
    console.log('üîÑ HYBRID Force collection sample...');
    
    try {
      // Enable captions
      const ccButton = document.querySelector('.ytp-subtitles-button');
      if (ccButton && ccButton.getAttribute('aria-pressed') !== 'true') {
        ccButton.click();
        await sleep(2000);
      }
      
      // Try to collect for 15 seconds
      const collectedCaptions = await monitorCaptionsForPeriod(15000);
      
      if (collectedCaptions.length > 0) {
        return collectedCaptions;
      }
      
      // If still nothing, try to get any text from video description or title
      const videoTitle = document.querySelector('h1.ytd-video-primary-info-renderer, #title h1')?.textContent?.trim();
      const videoDescription = document.querySelector('#description')?.textContent?.trim()?.substring(0, 200);
      
      if (videoTitle || videoDescription) {
        console.log('üìù HYBRID Using video metadata as fallback');
        const fallbackText = [videoTitle, videoDescription].filter(Boolean).join('. ');
        
        return [{
          start: 0,
          end: 10,
          duration: 10,
          text: `Video content: ${fallbackText} (Note: This is video metadata, not actual captions. Try using "Collect" feature while playing the video.)`
        }];
      }
      
      return null;
    } catch (error) {
      console.error('‚ùå HYBRID Force collection failed:', error);
      return null;
    }
  }

  function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

})();